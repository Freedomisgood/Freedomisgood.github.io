<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><meta name="author" content="Mrli"><meta name="renderer" content="webkit"><meta name="copyright" content="Mrli"><meta name="keywords" content="Mrli's Blog"><meta name="description" content="想和你讲，说了会心动 ，缄默会心安。"><meta name="Cache-Control" content="no-cache"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>深度学习 · Mr.li's Blog</title><link rel="stylesheet" href="/css/style.css?v=2018.7.9"><link rel="stylesheet" href="/css/animation.css?v=2018.7.9"><link rel="icon" href="/img/assets/favicon.ico"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.6"><!-- scripts--><script>(function( w ){
  "use strict";
  // rel=preload support test
  if( !w.loadCSS ){
    w.loadCSS = function(){};
  }
  // define on the loadCSS obj
  var rp = loadCSS.relpreload = {};
  // rel=preload feature support test
  // runs once and returns a function for compat purposes
  rp.support = (function(){
    var ret;
    try {
      ret = w.document.createElement( "link" ).relList.supports( "preload" );
    } catch (e) {
      ret = false;
    }
    return function(){
      return ret;
    };
  })();

  // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
  // then change that media back to its intended value on load
  rp.bindMediaToggle = function( link ){
    // remember existing media attr for ultimate state, or default to 'all'
    var finalMedia = link.media || "all";

    function enableStylesheet(){
      link.media = finalMedia;
    }

    // bind load handlers to enable media
    if( link.addEventListener ){
      link.addEventListener( "load", enableStylesheet );
    } else if( link.attachEvent ){
      link.attachEvent( "onload", enableStylesheet );
    }

    // Set rel and non-applicable media type to start an async request
    // note: timeout allows this to happen async to let rendering continue in IE
    setTimeout(function(){
      link.rel = "stylesheet";
      link.media = "only x";
    });
    // also enable media after 3 seconds,
    // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
    setTimeout( enableStylesheet, 3000 );
  };

  // loop through link elements in DOM
  rp.poly = function(){
    // double check this to prevent external calls from running
    if( rp.support() ){
      return;
    }
    var links = w.document.getElementsByTagName( "link" );
    for( var i = 0; i < links.length; i++ ){
      var link = links[ i ];
      // qualify links to those with rel=preload and as=style attrs
      if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
        // prevent rerunning on link
        link.setAttribute( "data-loadcss", true );
        // bind listeners to toggle media back
        rp.bindMediaToggle( link );
      }
    }
  };

  // if unsupported, run the polyfill
  if( !rp.support() ){
    // run once at least
    rp.poly();

    // rerun poly on an interval until onload
    var run = w.setInterval( rp.poly, 500 );
    if( w.addEventListener ){
      w.addEventListener( "load", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    } else if( w.attachEvent ){
      w.attachEvent( "onload", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    }
  }


  // commonjs
  if( typeof exports !== "undefined" ){
    exports.loadCSS = loadCSS;
  }
  else {
    w.loadCSS = loadCSS;
  }
}( typeof global !== "undefined" ? global : this ) );</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" defer></script><script src="/js/main.js?v=2018.7.9" defer></script><!-- fancybox--><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script><!-- busuanzi--><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></head><body><section class="profile-close" id="cxo-profile"><div class="profile-avatar"><i class="fa fa-caret-left"></i><img src="https://avatars1.githubusercontent.com/u/31088082?s=400&amp;u=7a99ff83916afb3f4c5312bd78a1be17fe0e34ed&amp;v=4"></div><!--.profile-saying
  i.fa.fa-comment
  .saying--><div class="cxo-profile-inner"><div class="profile-name">Mrli</div><div class="profile-signature">别装作很努力,<br>因为结局不会陪你演戏。</div><div class="contacts"><div>Contacts:</div><span><a href="http://sighttp.qq.com/msgrd?v=1&amp;uin=1063052964" target="_black">QQ</a></span><span><a href="https://www.cnblogs.com/nymrli/" target="_black">博客园</a></span></div><div class="read-progress"></div></div></section><header id="cxo-intro" style="height: 60vh;background-image: url(/img/intro/index-bg.png);"><nav id="cxo-intro-nav"><section><div class="intro-nav-title"><a href="/">Mr.li's Blog</a></div><div class="intro-nav-label-box"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div><i class="fa fa-bars intro-nav-menu"><div class="intro-nav-drop"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div></i><div class="clear"></div></section></nav><h1 class="post-title">深度学习</h1><div class="post-intros"><div class="post-intro-meta"><span class="post-intro-time"><i class="post-intro-calendar fa fa-edit"></i><span>2021/11/26</span></span><span class="busuanzi-pv" id="busuanzi_container_page_pv"><i class="post-intro-calendar fa fa-user-o"></i><span id="busuanzi_value_page_pv"></span></span><span class="post-intro-tags"><a class="intro-tag fa fa-tag" href="javascript:void(0)" date-tags="机器学习"> 机器学习</a></span></div><div class="post-intro-read"><span> Word count: <span class="post-count">7,246</span> | Reading time: <span class="post-count">31</span>min</span></div></div></header><article class="cxo-up" id="cxo-content-outer"><section id="cxo-content-inner"><article class="article-entry" id="post"><h1 id="深度学习神经网络"><a class="markdownIt-Anchor" href="#深度学习神经网络"></a> 深度学习——神经网络</h1>
<h2 id="构建网络的总原则"><a class="markdownIt-Anchor" href="#构建网络的总原则"></a> 构建网络的总原则</h2>
<p>一、增大网络容量，直到过拟命<br>
二、采取措施抑制过拟合<br>
三、继续增大网络容量，直到过拟合</p>
<h2 id="线性回归"><a class="markdownIt-Anchor" href="#线性回归"></a> 线性回归</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Commented out IPython magic to ensure Python compatibility.</span></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># %matplotlib inline</span></span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>,<span class="number">80</span>,<span class="number">50</span>)</span><br><span class="line">y = <span class="number">3</span>*x + np.random.randn(<span class="number">50</span>)*<span class="number">15</span></span><br><span class="line"><span class="comment"># print(x,y,sep='\n')</span></span><br><span class="line">plt.scatter(x,y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = keras.Sequential()</span><br><span class="line"><span class="comment"># 增加一层：全连接层</span></span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>,input_dim=<span class="number">1</span>))</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">             loss=<span class="string">'mse'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="comment"># 方法一</span></span><br><span class="line">model.fit(x,y,epochs=<span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line"><span class="comment">#for setp in range(3001):</span></span><br><span class="line"><span class="comment">#    cost = model.train_on_batch(x_data,y_data)</span></span><br><span class="line"><span class="comment">#    if step % 500 == 0:</span></span><br><span class="line"><span class="comment">#        print('cost:',cost)</span></span><br><span class="line"><span class="comment">#w,b = model.layers[0].get_weights()</span></span><br><span class="line"></span><br><span class="line">predict_y = model.predict(x)</span><br><span class="line">plt.scatter(x,y,s=<span class="number">10</span>,c=<span class="string">'r'</span>)</span><br><span class="line">plt.plot(x,predict_y)</span><br></pre></td></tr></table></figure>
<p>非线性回归</p>
<h2 id="激活函数"><a class="markdownIt-Anchor" href="#激活函数"></a> 激活函数</h2>
<p>softmax</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mi>i</mi></msup><mrow><msub><mo>∑</mo><mi>j</mi></msub><msup><mi>e</mi><mi>j</mi></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">S_{i}=\frac{e^{i}}{\sum_{j} e^{j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.6926869999999998em;vertical-align:-0.667227em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0254599999999998em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.14964714285714287em;"><span style="top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46032428571428574em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857144em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9020857142857143em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.667227em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<h3 id="sigmod"><a class="markdownIt-Anchor" href="#sigmod"></a> sigmod:</h3>
<h4 id="logistic"><a class="markdownIt-Anchor" href="#logistic"></a> logistic:</h4>
<blockquote>
<p>范围是[0,1]</p>
</blockquote>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi mathvariant="normal">e</mi><mi>t</mi></msup><mrow><msup><mi mathvariant="normal">e</mi><mi>t</mi></msup><mo>+</mo><mn>1</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi mathvariant="normal">e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(t)=\frac{\mathrm{e}^{t}}{\mathrm{e}^{t}+1}=\frac{1}{1+\mathrm{e}^{-t}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.406571em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.00324em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7253428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8703428571428571em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2484389999999999em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7253428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<h3 id="relu"><a class="markdownIt-Anchor" href="#relu"></a> reLU</h3>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)=max(0,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></p>
<h3 id="tanh"><a class="markdownIt-Anchor" href="#tanh"></a> tanh</h3>
<blockquote>
<p>跟sigmoid函数很像,但是范围是[-1,1],而不是[0,1],实质是sigmoid函数平移</p>
</blockquote>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>sinh</mi><mo>⁡</mo><mi>x</mi></mrow><mrow><mi>cosh</mi><mo>⁡</mo><mi>x</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\tanh(x)=\frac{\sinh x}{\cosh x}=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight">cosh</span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathdefault mtight">x</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight">sinh</span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.3906960000000002em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.987365em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5935428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7026642857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7385428571428572em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8476642857142858em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>TensorFlow中其他的函数：</p>
<p>●tf.nn.elu(x)： 指数线性单元； 如果输入小于0， 返回exp(x)-1； 否<br>
则， 返回x；<br>
●tf.softsign(x)： 返回x/(abs(x)+1)；<br>
●tf.nn.bias_add(value,bias)： 增加一个bias到value。</p>
<h2 id="tensorflow"><a class="markdownIt-Anchor" href="#tensorflow"></a> Tensorflow:</h2>
<blockquote>
<ul>
<li>张量——数据  :</li>
<li>多维数组,阶:张量的维数</li>
<li>计算图——神经网络</li>
<li>搭建神经网络的计算过程,只搭建,不运算</li>
</ul>
<p>会话——执行计算图===&gt;优化线上的权重====&gt;权重</p>
</blockquote>
<p>神经网络实现过程</p>
<blockquote>
<p>1.准备数据集,提取特征,作为输入<br>
2.搭建NN结构,从输入到输出==&gt;(NN前向传播)</p>
<p>3.大量特征数据喂给NN,迭代优化NN参数==&gt;(NN反向传播)</p>
<p>4.使用训练好的模型预测和分类</p>
</blockquote>
<p><strong><mark><mark>&gt;八股:准备,前传,后传,迭代&lt;</mark></mark></strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x  = tf.placehold(tf.float32,shape=(<span class="number">1</span>,<span class="number">2</span>))   <span class="comment">#占位符</span></span><br><span class="line">sess.run(要计算的节点,feed_dict=&#123;x:[[<span class="number">1.3</span>,<span class="number">2.0</span>]]&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Init_op =  tf.global_variables_initializer()</span><br><span class="line">sess.run(Init_op)</span><br></pre></td></tr></table></figure>
<p>y = matmul(x,w1)`相乘</p>
<h1 id="tensorflow机器学习项目实战笔记"><a class="markdownIt-Anchor" href="#tensorflow机器学习项目实战笔记"></a> 《TensorFlow机器学习项目实战》笔记</h1>
<h2 id="张量"><a class="markdownIt-Anchor" href="#张量"></a> 张量</h2>
<p>TensorFlow基于张量数据管理。 张量是数学领域的概念， 并且被开<br>
发为向量和矩阵的线性代数项的泛化。 一个张量就是一个张量类的实例， 是绑定了相关运算的一个<strong>特定类型的多维数组</strong>。</p>
<p>张量的属性</p>
<ul>
<li>有一个静态的类型和动态的维数</li>
<li>只有张量类型的对象才能在计算图的节点中<br>
传递。</li>
<li>秩rank</li>
<li>数据类型type</li>
<li>形状shape</li>
</ul>
<h2 id="numpy数组到tensorflow张量"><a class="markdownIt-Anchor" href="#numpy数组到tensorflow张量"></a> numpy数组到TensorFlow张量</h2>
<p>TensorFlow与numpy是可互操作的， 通常调用eval()函数会返回<br>
numpy对象。因为张量对象只是一个操作结果的符号化句柄， 所以它并不持有该操作的结果 ,必须使用eval()方法来获得实际的<br>
值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment">#we import tensorflow</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#we import numpy</span></span><br><span class="line">sess = tf.Session() <span class="comment">#start a new Session Object</span></span><br><span class="line">x_data = np.array([[<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>],</span><br><span class="line">[<span class="number">3.</span>,<span class="number">2.</span>,<span class="number">6.</span>]]) <span class="comment"># 2x3 matrix</span></span><br><span class="line">x = tf.convert_to_tensor(x_data,</span><br><span class="line">dtype=tf.float32) <span class="comment">#Finally, we create the</span></span><br><span class="line"><span class="comment">#tensor, starting from the fload 3x matrix</span></span><br></pre></td></tr></table></figure>
<p>tf.convert_to_tensor``： 该方法将Python对象转化为tensor对象。 它的<br>
输入可以是tensor对象、 numpy数组、 Python列表和Python标量。</p>
<p>数据流图(data flow graph)</p>
<blockquote>
<p>数据流图是完整的TensorFlow计算</p>
</blockquote>
<ul>
<li>
<p>节点(node) 表示操作(operation) ,实现数学运算， 同时也表示数据或变量的供给(feed) ， 或输出结果 。一旦其输入边缘上的所有张量都到位， 则开始异步地并行执行</p>
</li>
<li>
<p>边(edge) 表示各操作之间流通的数据 ,描述节点之间的输入/输出关系。 这些数据边缘专门传输张量</p>
</li>
</ul>
<p>计算图(computation graph)</p>
<blockquote>
<p>由用户在创建张量(tensor) 和操作(op</p>
</blockquote>
<p>有用的操作对象方法如下：<br>
●tf.Operation.type： 返回操作的类型(例如， MatMul) ；<br>
●tf.Operation.inputs： 返回表示操作的输入张量对象列表；<br>
●tf.Graph.get_operations()： 返回计算图中的操作列表；<br>
●tf.Graph.version： 返回计算图的版本信息。</p>
<h2 id="变量"><a class="markdownIt-Anchor" href="#变量"></a> 变量</h2>
<blockquote>
<p>正如字面意思所示,是个变化的量。在TensorFlow具体表现为需要更新的参数</p>
</blockquote>
<p>在大多数计算中， 会多次执行计算图。 大多数张量的生存周期不会<br>
超过单次执行周期。 然而， 变量是一种特殊的操作， 它返回一个持久<br>
的、 可变的张量的句柄， 存活于多次计算图执行之中。 对于TensorFlow<br>
的机器学习应用， 模型的参数通常存储在变量中， 并且在运行模型的训<br>
练阶段被更新。</p>
<h2 id="placehold"><a class="markdownIt-Anchor" href="#placehold"></a> placehold</h2>
<p>给之后喂给的数据占位</p>
<h2 id="会话"><a class="markdownIt-Anchor" href="#会话"></a> 会话</h2>
<p>客户端程序通过创建会话(Session)与TensorFlow系统交互。<br>
Session对象是运行环境的表示。Session对象开始为空，当程序员创建不同的操作和张量时，它们将被自动添加到Session，直到Run方法被调用，才开始运算。<br>
Run方法输入是需要计算的操作，以及一组可选的张量，用来代替图中某些节点的输出。<br>
如果我们调用这个方法，并且有命名操作所依赖的操作，Session对象将执行所有这些操作，然后继续执行命名操作。<br>
用以下简单的代码可以创建一个会话：<br>
s=tf.Session()</p>
<p>矩阵运算</p>
<p>转置、 乘法、 获取行列式和逆</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf. transpose(x). eval()<span class="comment"># Transpose</span></span><br><span class="line">tf. matmul(x,y). eval()<span class="comment"># Matrix</span></span><br><span class="line">tf. matrix determinant(floatx). eval()<span class="comment"># 行列式</span></span><br><span class="line">tf.matrix_inverse(floatx).eval() <span class="comment"># 求逆</span></span><br></pre></td></tr></table></figure>
<p>约简(reduction) 是一种跨维度张量操作， 计算结果比原张量缩减<br>
一个维度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line">In[<span class="number">2</span>]: sess=tf. InteractiveSession()</span><br><span class="line"></span><br><span class="line">In[<span class="number">3</span>]:x=tf. constant([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">                    [<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">                    [<span class="number">-1</span>,<span class="number">2</span>,<span class="number">-3</span>]])</span><br><span class="line"></span><br><span class="line">In[<span class="number">5</span>]: tf.reduce_prod(x, reduction_indices=<span class="number">1</span>). eval() <span class="comment"># reduce prod,行操作,0为列操作</span></span><br><span class="line">    <span class="number">0</span>ut[<span class="number">5</span>]: array([<span class="number">6</span>,<span class="number">6</span>,<span class="number">-6</span>], dtype=int32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: tf. reduce_min(x, reduction_indices=<span class="number">1</span>). eval()<span class="comment"># reduce min</span></span><br><span class="line">    <span class="number">0</span>ut[<span class="number">6</span>]: array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">-3</span>], dtype=int32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: tf. reduce_max(x, reduction_indices=<span class="number">1</span>). eval()<span class="comment"># reduce max</span></span><br><span class="line">    <span class="number">0</span>ut[<span class="number">7</span>]: array([<span class="number">3</span>,<span class="number">3</span>,<span class="number">-1</span>], dtype=int32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: tf. reduce_mean(x, reduction indices=<span class="number">1</span>). eval()<span class="comment"># reduce mean</span></span><br><span class="line">    <span class="number">0</span>ut[<span class="number">8</span>]: array([ <span class="number">2</span>,<span class="number">2</span>,<span class="number">-2</span>], dtype=int32) </span><br><span class="line">In[<span class="number">9</span>]: tf. reduce_all(boolean_tensor, reduction_indices=<span class="number">1</span>). eval()<span class="comment"># reduce all </span></span><br><span class="line">    Out[<span class="number">9</span>]: array([ <span class="keyword">False</span>, <span class="keyword">False</span>, <span class="keyword">False</span>], dtype=bool)</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: tf. reduce_any(boolean_tensor,</span><br></pre></td></tr></table></figure>
<p>序列实用程序包括诸如argmin和argmax(显示维度的最小和最大<br>
值) ， listdiff(显示列表之间的交集的补码) ， where(显示张量上的真<br>
实值的索引) 和unique(在列表上去除重复的元素) 。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf sess=tf. InteractiveSession()</span><br><span class="line">x=tf. constant([[<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">-5</span>],</span><br><span class="line">…:[<span class="number">0</span>,<span class="number">3</span>,<span class="number">-2</span>,<span class="number">5</span>],……:[<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>],…:[<span class="number">6</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">0j</span>j)</span><br><span class="line">listx=tf. constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line">listy=tf. constant([<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">boolx=tf. constant([[ <span class="keyword">True</span>, <span class="keyword">False</span>],</span><br><span class="line">[ <span class="keyword">False</span>, <span class="keyword">True</span>]])</span><br><span class="line">                             </span><br><span class="line">tf. argmin(x,<span class="number">1</span>). eval()<span class="comment"># Position of the maximum value of columns</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line">                             </span><br><span class="line">tf. argmax(x,<span class="number">1</span>). eval()<span class="comment"># Position of the minimum value of rows</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>])</span><br><span class="line">                             </span><br><span class="line">tf. listdiff(listx, listy)[<span class="number">0</span>]. eval()<span class="comment">#List differences</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">7</span>], dtype=int32)</span><br><span class="line">                             </span><br><span class="line">tf.where(boolx). eval()<span class="comment"># Show true values</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([[o,<span class="number">0</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">                             </span><br><span class="line">tf. unique(listx)[<span class="number">0</span>]. eval()<span class="comment"># Unique values in list</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], dtype=int32)</span><br></pre></td></tr></table></figure>
<p>形状变换 :</p>
<p>例如squeeze和expand_dims。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line">In [<span class="number">2</span>]: sess=tf. InteractiveSession()</span><br><span class="line">In [<span class="number">3</span>]:x=tf. constant([[<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">-5</span>],</span><br><span class="line">                    ……:[<span class="number">0</span>,<span class="number">3</span>,<span class="number">-2</span>,<span class="number">5</span>],</span><br><span class="line">                    …:[<span class="number">4</span>,<span class="number">3153</span>,</span><br><span class="line">                    …:[<span class="number">6</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">0</span>]])</span><br><span class="line">tf. shape(x). eval()<span class="comment"># Shape of the tensor</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">4</span>,<span class="number">4</span>], dtype=int32)</span><br><span class="line">tf. size(x). eval()<span class="comment"># size of the tensor</span></span><br><span class="line">&gt;&gt;&gt;<span class="number">16</span></span><br><span class="line">tf. rank(x). eval()<span class="comment"># rank of the tensor</span></span><br><span class="line">&gt;&gt;&gt;<span class="number">2</span></span><br><span class="line">tf. reshape(x,[<span class="number">8</span>,<span class="number">2</span>]). eval()<span class="comment">#</span></span><br><span class="line">converting to a <span class="number">10</span>×<span class="number">2</span> matrix</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">array([[ <span class="number">2</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">-5</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">3</span>],</span><br><span class="line">[<span class="number">-2</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">4</span>],</span><br><span class="line">[<span class="number">3</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">5</span>,<span class="number">3</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">4</span>,<span class="number">0</span>]], dtype=int32)</span><br><span class="line">tf. squeeze(x). eval()<span class="comment"># squeezing</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([[ <span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">-5</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">3</span>,<span class="number">-2</span>,<span class="number">5</span>],</span><br><span class="line"><span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">0</span>]], dtype=int32)</span><br><span class="line">tf. expand_dims(x,<span class="number">1</span>). eval()<span class="comment"># Expanding dims</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">array([[[ <span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">-5</span>]],</span><br><span class="line">[[ <span class="number">0</span>,<span class="number">3</span>,<span class="number">-2</span>,<span class="number">5</span>]],</span><br><span class="line">[[<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">3</span>]],</span><br><span class="line">[i <span class="number">6</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">0j</span>ji, dtype=int32)</span><br></pre></td></tr></table></figure>
<p>切片(slicing) 和连接(joining) :提取矩阵切片、 拆分、 添加填充(add padding) ， 以及打包(pack) 和解包(unpack) 行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf sess=tf. InteractiveSession()</span><br><span class="line">t_matrix=tf. constant([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">                    ……:[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],</span><br><span class="line">                    …:[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]])</span><br><span class="line">t_array=tf. constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">5</span>])</span><br><span class="line">t array2=tf. constant([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]) tf. </span><br><span class="line"></span><br><span class="line">slice(t _matrix,[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]). eval()</span><br><span class="line"><span class="comment"># cutting an slice</span></span><br><span class="line">&gt;&gt;&gt;array([[<span class="number">5</span>,<span class="number">6</span>],</span><br><span class="line">[<span class="number">8</span>,<span class="number">9</span>]], dtype=int32)</span><br><span class="line">tf. split(<span class="number">0</span>,<span class="number">2</span>,t_array)<span class="comment"># splitting the array in two</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">[&lt;tf. Tensor <span class="string">' split:0'</span> shape=(<span class="number">4</span>,) dtype=int32&gt;,</span><br><span class="line">&lt;tf. Tensor <span class="string">' split:1'</span> shape=(<span class="number">4</span>,) dtype=int32&gt;]</span><br><span class="line"></span><br><span class="line">tf. tile([<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>]). eval()<span class="comment"># tiling this little tensor 3 times重复</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>], dtype=int32)</span><br><span class="line"></span><br><span class="line">tf. pad(t_matrix,[[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">1</span>]]). evai()<span class="comment">#padding</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array(i[o,o,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">0</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">0</span>],[o<span class="number">.0</span><span class="number">.7</span><span class="number">.8</span><span class="number">.9</span><span class="number">.01</span>.</span><br><span class="line">[o,o,o,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]], dtype=int32)</span><br><span class="line"></span><br><span class="line">tf. concat(<span class="number">0</span>,[t_array, t_array2]). eval()<span class="comment"># concatenating list</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,</span><br><span class="line"><span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], dtype=int32)</span><br><span class="line"></span><br><span class="line">tf. pack([t_array,t_array2]). eval()<span class="comment"># packing 拼接</span></span><br><span class="line"><span class="number">0</span>ut[<span class="number">11</span>]:array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">6</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]], dtype=int32)</span><br><span class="line">    </span><br><span class="line">sess.run(tf. unpack(t_matrix))<span class="comment">#Unpacking, we need the run method to view the tensors</span></span><br><span class="line">&gt;&gt;&gt;[array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],dtype=int32),</span><br><span class="line">array([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=int32),</span><br><span class="line">array([<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>];dtype=int32)</span><br><span class="line">    </span><br><span class="line">In [<span class="number">13</span>]: tf. reverse(t_matrix,</span><br><span class="line">[ <span class="keyword">False</span>, <span class="keyword">True</span>]). eval()<span class="comment"># Reverse matrix,行不变,列反转</span></span><br><span class="line"><span class="number">0</span>ut[<span class="number">13</span>]: array([[<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">6</span>,<span class="number">5</span>,<span class="number">41</span>;</span><br><span class="line"><span class="number">9</span>,<span class="number">8</span>,<span class="number">7</span>]], dtype=int32)</span><br></pre></td></tr></table></figure>
<p>从磁盘读取信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列表格式——CSV </span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess=tf.Session()</span><br><span class="line">filename_queue= tf.train.string_input_producer(</span><br><span class="line">tf.train.match_filenames_once(<span class="string">"./*.csv"</span>),</span><br><span class="line">shuffle=<span class="keyword">True</span>)</span><br><span class="line">reader=tf.TextLineReader(skip_header_lines=<span class="number">1</span>)</span><br><span class="line">key, value=reader.read(filename_queue)</span><br><span class="line">record_defaults=[[<span class="number">0.</span>],[<span class="number">0.</span>],[<span class="number">0</span>],[<span class="number">0.</span>],[<span class="string">""</span>]]</span><br><span class="line">col1, col2, col3, col4, col5=</span><br><span class="line">tf.decode_csv(value,</span><br><span class="line">record_defaults=record_defaults)<span class="comment"># Convert CSV</span></span><br><span class="line">records to tensors.Each</span><br><span class="line"><span class="comment"># column maps to one tensor.</span></span><br><span class="line">features=tf.pack([ col1, col2, col3, col4])</span><br><span class="line">tf.initialize_all_variables().run(session=sess)</span><br><span class="line">coord=tf.train.Coordinator()</span><br><span class="line">threads=</span><br><span class="line">tf.train.start_queue_runners(coord=coord, sess=sess)</span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>):</span><br><span class="line">example=sess.run([ features])</span><br><span class="line">print(example)</span><br><span class="line">coord.request_stop()</span><br><span class="line">coord.join(threads)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载和处理图像</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf sess=tf.Session()</span><br><span class="line">filename_queue=</span><br><span class="line">tf.train.string_input_producer(tf.train.match_filenames_once(<span class="string">'./blue_jay.jpg'</span>))</span><br><span class="line">reader=tf.WholeFileReader()</span><br><span class="line">key, value= reader.read(filename_queue)</span><br><span class="line">image=tf.image.decode_jpeg(value)</span><br><span class="line">fliplmageUpDown=tf.image.encode _jpeg(tf.image.fli </span><br><span class="line">p_up_down(image))<span class="comment"># 获得上下翻转的图片                                   </span></span><br><span class="line">fliplmageleftRight=tf.image.encode_jpeg(tf.image.flip_left_right(image))<span class="comment"># 获得左右翻转的图片    </span></span><br><span class="line">tf.initialize_all_variables().run(session=sess)</span><br><span class="line">coord=tf.train.Coordinator()</span><br><span class="line">threads=</span><br><span class="line">tf.train.start_queue_runners(coord=coord, sess=sess)</span><br><span class="line">example=sess.run(fliplmageLeftRight)</span><br><span class="line"><span class="keyword">print</span> example file=open (<span class="string">"flippedUpDown.jpg"</span>,<span class="string">"wb+"</span>)</span><br><span class="line">file.write (fliplmageUpDown.eval(session=sess))<span class="comment"># 写入上下翻转图</span></span><br><span class="line">file.close()</span><br><span class="line">file=open (<span class="string">"flippedLeftRight.jpg"</span>,<span class="string">"wb+"</span>)<span class="comment"># 写入左右翻转图</span></span><br><span class="line">file.write</span><br><span class="line">(fliplmageLeftRight.eval(session=sess))</span><br><span class="line">file.close()</span><br></pre></td></tr></table></figure>
<p>流程:</p>
<ol>
<li>创建一个文件队列对象:<code>tf.train.string_input_producer(tf.train.match_filenames_once('xxx'))</code></li>
<li>创建一个reader对象</li>
<li>读取,并解码</li>
<li>提取特征</li>
<li><code>initialize_all_variables</code>-&gt;<code>Coordinator</code>-&gt;<code>start_queue_runners</code>-&gt;run</li>
</ol>
<h2 id="logit函数"><a class="markdownIt-Anchor" href="#logit函数"></a> logit函数</h2>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">logit</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="normal">p</mi><mo stretchy="false">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mi mathvariant="normal">p</mi><mrow><mn>1</mn><mo>−</mo><mi mathvariant="normal">p</mi></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\operatorname{logit}(\mathrm{p})=\log \left(\frac{\mathrm{p}}{1-\mathrm{p}}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">i</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">p</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathrm mtight">p</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">p</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></p>
<p>该函数实现了从区间[0,1]到区间(-∞,+∞)之间的映射。 那么我们只要将y用一个输入的线性函数替换， 那么就实现了输入的线性变化和区间[0,1]之间的映射。</p>
<p><img src="/2019/09/19/深度学习/E:%5Chexo%5Csource_posts%5C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5Clogit.jpg" alt="logit"></p>
<h2 id="logistic函数"><a class="markdownIt-Anchor" href="#logistic函数"></a> logistic函数</h2>
<p>对数几率函数的逆函数</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi mathvariant="normal">logit</mi><mo>⁡</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">logistic</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">ep</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\operatorname{logit}^{-1}(\alpha)=\operatorname{logistic}(\alpha)=\frac{1}{1+\exp (-\alpha)}=\frac{\operatorname{ep}(\alpha)}{\exp (\alpha)+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.148448em;vertical-align:-0.25em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">i</span><span class="mord mathrm">t</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8984479999999999em;"><span style="top:-3.14734em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">i</span><span class="mord mathrm">s</span><span class="mord mathrm">t</span><span class="mord mathrm">i</span><span class="mord mathrm">c</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.365108em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight">exp</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight">p</span></span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>这是一个Sigmoid函数。<br>
Logistic函数将使得我们能够在我们的回归任务表示为二项选择。</p>
<p><img src="/2019/09/19/深度学习/E:%5Chexo%5Csource_posts%5C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%5Csigmoid.jpg" alt="sigmoid"></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi mathvariant="normal">e</mi><mi>t</mi></msup><mrow><msup><mi mathvariant="normal">e</mi><mi>t</mi></msup><mo>+</mo><mn>1</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi mathvariant="normal">e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(t)=\frac{\mathrm{e}^{t}}{\mathrm{e}^{t}+1}=\frac{1}{1+\mathrm{e}^{-t}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.406571em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.00324em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7253428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8703428571428571em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2484389999999999em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7253428571428571em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>一般的解释就是t为一个独立变量， 该函数将t映射到区间[0,1]之<br>
间。 但是我们提升了这个模型， 将t转变为变量x的一个线性映射(当x<br>
是一个多变量的向量时， t就是该向量中各个元素的线性组合) 。</p>
<p>我们可以将t表示如下：<br>
t=wx+b<br>
我们就能够得到以下方程 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">logit</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="normal">p</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">In</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mi>p</mi><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac><mo fence="true">)</mo></mrow><mo>=</mo><mi>w</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">\operatorname{logit}(\mathrm{p})=\operatorname{In}\left(\frac{p}{1-p}\right)=w x+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">l</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mord mathrm">i</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">p</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mop"><span class="mord mathrm">I</span><span class="mord mathrm">n</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">p</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span></p>
<p>对于所有的元素， 我们计算了回归方程， 得出如下概率。 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo>=</mo><mfrac><msup><mi mathvariant="normal">e</mi><mrow><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi></mrow></msup><mrow><mn>1</mn><mo>+</mo><msup><mi mathvariant="normal">e</mi><mrow><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{p}=\frac{\mathrm{e}^{\beta_{0}+\beta_{1} x}}{1+\mathrm{e}^{\beta_{0}+\beta_{1} x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">p</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.4837159999999998em;vertical-align:-0.44079599999999997em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0429199999999998em;"><span style="top:-2.617535em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8178071428571428em;"><span style="top:-2.8217785714285717em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:-0.05278em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29964em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:-0.05278em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29964em;"><span></span></span></span></span></span></span><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9270285714285713em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:-0.05278em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29964em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:-0.05278em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29964em;"><span></span></span></span></span></span></span><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44079599999999997em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>线性函数的参数起什么作用呢？ 它们可以改变直线的斜率和<br>
Sigmoid函数零的位置。 通过调整线性方程中的参数， 来缩小预测值与<br>
真实值之间的差距。</p>
<p>Logistic函数的属性<br>
函数空间中每个曲线都可以被描述成它所应用的可能目标。 具体到Logistic函数：<br>
●事件的可能性p依赖于一个或者多个变量。 比如， 根据之前的资<br>
历,预测获奖的可能性。<br>
●对于特定的观察， 估算事件发生的可能性。<br>
●预测改变独立变量对二项响应的影响。<br>
●通过计算可能性， 将观测分配到某个确定的类。</p>
<p>损失函数</p>
<p>loss <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>=</mo><mo>−</mo><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>y</mi><mi>i</mi></msub><mo>∙</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>y</mi><mi>p</mi><mi>r</mi><mi>e</mi><msub><mi>d</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo>+</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo>∙</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><mi>y</mi><mi>p</mi><mi>r</mi><mi>e</mi><msub><mi>d</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">=-\sum_{i} y_{i} \bullet \log \left(y p r e d_{i}\right)+\left(1-y_{i}\right) \bullet \log \left(1-y p r e d_{i}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0497100000000001em;vertical-align:-0.29971000000000003em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></p>
<p>该损失函数的主要性质就是偏爱相似行为， 而当误差超过0.5的时<br>
候， 惩罚会急剧增加。</p>
<p>多类分类应用——Softmax回归</p>
<p>当我们面对多于二类的情况， 通常有两种方法： 一对多和一对所<br>
有。<br>
●第一类技术计算多个模型。 针对每个类都计算一个“一vs所有<br>
(one against all) ”的概率。<br>
●第二类技术只计算出一个概率集合， 每个概率表示属于其中某一<br>
类的可能性。<br>
●第二种技术的输出是Softmax回归格式， 这是Logistic回归对于n类<br>
的泛化。</p>
<p>损失函数</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><msub><mo>∑</mo><mi>c</mi></msub><msub><mi>y</mi><mi>c</mi></msub><mo>∙</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>y</mi><mi>p</mi><mi>r</mi><mi>e</mi><msub><mi>d</mi><mi>c</mi></msub><mo fence="true">)</mo></mrow><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><msub><mo>∑</mo><mi>c</mi></msub><msub><mi>y</mi><mi>c</mi></msub><mo>∙</mo><mfrac><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>x</mi><mi>c</mi></msub></mrow></msup><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>c</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>x</mi><mi>j</mi></msub></mrow></msup><mo fence="true">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">loss=\sum_{i} \sum_{c} y_{c} \bullet \log \left(y p r e d_{c}\right)=\sum_{i} \sum_{c} y_{c} \bullet \frac{e^{-x_{c}}}{\sum_{j=0}^{c-1} \log \left(e^{-x_{j}}\right)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0497100000000001em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0497100000000001em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0016819999999999613em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.817685em;vertical-align:-0.8303200000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.987365em;"><span style="top:-2.4925em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8646357142857142em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-2.9043214285714285em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight">lo<span style="margin-right:0.01389em;">g</span></span><span class="minner mtight"><span class="mopen sizing reset-size3 size6 mtight delimcenter" style="top:0.07500000000000001em;"><span class="mtight">(</span></span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8881000000000001em;"><span style="top:-2.9714357142857146em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.65952em;"></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5091600000000001em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mclose sizing reset-size3 size6 mtight delimcenter" style="top:0.07500000000000001em;"><span class="mtight">)</span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8476642857142858em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23056em;"><span style="top:-2.3em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8303200000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<h2 id="感知器算法"><a class="markdownIt-Anchor" href="#感知器算法"></a> 感知器算法</h2>
<blockquote>
<p>简单来说就是一个二元分类函数</p>
</blockquote>
<p>简化版的感知器算法如下：<br>
① 以一个随机分布初始化权值和偏差(通常比较小) ；<br>
② 选择一个输入向量， 并将其放入神经网络中；<br>
③ 将输入与权重相乘， 并加上偏差， 计算网络的输出y’；<br>
④ 感知器的函数如下：</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.15999999999999992em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mi>f</mi><mtext>  </mtext><mi>w</mi><mo>⋅</mo><mi>x</mi><mo>+</mo><mi>b</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">f(x)=\left\{\begin{array}{ll}{1} &amp; {if \; w \cdot x+b&gt;0} \\ {0} &amp; otherwise \end{array}\right.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">{</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">1</span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-3.61em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span></span><span style="top:-2.4099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">o</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>⑤ 如果y′≠y， 将权重wi加上Δw=yxi；</p>
<p>⑥ 返回第②步。</p>
<h2 id="tensorflow中损失优化方法"><a class="markdownIt-Anchor" href="#tensorflow中损失优化方法"></a> TensorFlow中损失优化方法</h2>
<p>●tf.train.GradientDescentOptimizer(learning_rate, use_locking,<br>
name)： 原始梯度下降方法， 唯一参数就是学习率。<br>
●tf.train.AdagradOptimizer： 自适应调整学习率， 累加历史梯度的平<br>
方， 作为分母， 防止有些方向的梯度值过大， 提高优化效率， 善于处理<br>
稀疏梯度。<br>
●tf.train.AdadeltaOptimizer： 扩展AdaGrad优化方法， 只累加最近的<br>
梯度值， 而不对整个历史上的梯度值进行累加。<br>
●tf.train.AdamOptimizertf.train.AdamOptimizer． (learningrate, beta1,<br>
beta2, epsilon, use locking, name)： 梯度的一阶矩估计和二阶矩估计动态<br>
调整每个参数的学习率。 Adam是自适应矩估计(Adaptive Moment<br>
Estimation) 的首字母缩写。</p>
<h2 id="sklearn预处理函数"><a class="markdownIt-Anchor" href="#sklearn预处理函数"></a> Sklearn预处理函数</h2>
<p>我们看一些下面的Sklearn数据预处理函数：<br>
●preprocessing.StandardScaler()： 数据正规化(Normalization) 是机<br>
器学习估计的一个常见要求， 为了模型能更好地收敛， 我们通常会将数<br>
据集预处理到一个零均值单位方差的高斯状分布。 通常， 我们会将数据<br>
的各个维度都减去它的均值， 然后乘上一个非零的数。 这个非零的数就<br>
是数据集的标准差。 对于该任务， 我们直接使用StandardScaler， 它已经<br>
实现了我们上面提到的操作。 它也保留了变换操作， 让我们可以直接用<br>
在测试集上。<br>
●StandardScaler .fit_transform()： 将数据调整到所需要的形式。<br>
StandardScaler对象会存储数据变化的变量， 这样我们可以把数据解正规<br>
化到原先的格式。<br>
●cross_validation.train_test_split： 该方法能够将数据集分割成训练<br>
集和测试集。 我们只需要提供两者的比例， 该方法能够自动帮我们处<br>
理</p>
<h2 id="书籍推荐"><a class="markdownIt-Anchor" href="#书籍推荐"></a> 书籍推荐</h2>
<p>了解tensorflow基础对象——《面向机器智能的tensorflow实践》</p>
<p>进阶操作tensor对象——《Tensorflow机器学习项目实战》</p>
<h2 id="hello-tensorflow"><a class="markdownIt-Anchor" href="#hello-tensorflow"></a> Hello TensorFlow</h2>
<blockquote>
<p><code>import tensorflow as tf</code>如果报错dtype…可以降低numpy的版本(从1.16-&gt;1.17)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">% matplotlib inline </span><br><span class="line">a=tf.random_normal([<span class="number">2</span>,<span class="number">20</span>])</span><br><span class="line">sess=tf.Session()</span><br><span class="line">out=sess.run(a)</span><br><span class="line">x,y=out</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt. show()</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">%matplotlib inline</span></span><br><span class="line"><span class="string">这是一条专门的命令，用于通知笔记本将matplotib图表直接显示在浏览器中。</span></span><br><span class="line"><span class="string">下面逐行分析其余代码，如果你不理解某些术语，请不必担心，后面章节还会一一进行讲解：</span></span><br><span class="line"><span class="string">1)用TensorFlow定义一个由随机数构成的2×20的矩阵，并将其赋给变量a。</span></span><br><span class="line"><span class="string">2)启动TensorFlow Session，并将其赋予一个ses对象。</span></span><br><span class="line"><span class="string">3)用sess.run()方法执行对象a，并将输出(NumPy数组)赋给ot。</span></span><br><span class="line"><span class="string">4)将这个2×20的矩阵划分为两个1×10的向量x和y。</span></span><br><span class="line"><span class="string">5)利用pyplot模块绘制散点图，x对应横轴，y对应纵轴。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<h3 id="sesstfsession"><a class="markdownIt-Anchor" href="#sesstfsession"></a> sess=tf.Session()</h3>
<p>Session对象在运行时负责对数据流图进行监督，并且是运行数据流图的主要接口。在本练习之后，我们还将对Session对象进行更为深入的探讨，但现在只需了解在TensorFow中，如果希望运行自己的代码，必须定义一个Session对象。上述代码将Session对象赋给了变量sess，以便后期能够对其进行访问。</p>
<ul>
<li>target指定了所要使用的执行引擎。对于大多数应用，该参数取为默认的空字符串。在分布式设置中使用Session对象时，该参数用于连接不同的tftrain Server实例(本书后续章节将对此进行介绍)。</li>
<li>graph参数指定了将要在Session对象中加载的Graph对象，其默认值为None，表示将使用当前默认数据流图。当使用多个数据流图时，最好的方式是显式传入你希望运行的Graph对象(而非在一个with语句块内创建Session对象)。</li>
<li>config参数允许用户指定配置Session对象所需的选项，如限制CPU或GPU的使用数目，为数据流图设置优化参数及日志选项等。</li>
</ul>
<p>Sesionnn()方法接收一个参数<strong>fetches</strong>，以及其他三个可选参数：<strong>feed_dict</strong>、options和rnn_metadata。本书不打算对options和run_metadata进行介绍，因为它们尚处在实验阶段(因此以后很可能会有变动)，且目前用途非常有限，但理解ed_dict非常重要，下文将对其进行讲解。</p>
<p>1.fetches参数<br>
fetches参数接收任意的数据流图元素(Op或Tensor对象)，后者指定了用户希望执行的对象。如果请求对象为Tensor对象，则rnun()的输出将为一NumPy数组：如果请求对象为一个Op，则输出将为None。</p>
<p>除了利用fetches获取Tensor对象输出外，还将看到这样的例子：有时也会赋予ftches一个指向某个Op的句柄，这是在运行中的一种有价值的用法。<br>
tf.initialize_all_variables()使是一个这样的例子，它会准备将要使用的所有TensorFow Variable对象(本章稍后将介绍Variable对象)。我们仍然将该Op传给etches参数，但Session.run()的结果将为None：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">执行初始化Variable对象所需的计算，但返回值为None sess.run(tf.initialize_all_variables())</span><br></pre></td></tr></table></figure>
<p>2.feed_dict参数</p>
<p>参数feed_dict用于覆盖数据流图中的Tensor对象值，它需要Python字典对象作为输入。字典中的“键”为指向应当被覆盖的Tensor对象的句柄，而字典的“值”可以是数字、字符串、列表或NumPy数组(之前介绍过)。这些“值”的类型必须与Tensor的“键”相同，或能够转换为相同的类型。下面通过一些代码来展示如何利用feed_dict重写之前的数据流图中a的值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">inport tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#创建Op、Tensor对象等(使用默认的数据流图)</span></span><br><span class="line">a=tf.add(<span class="number">2</span>，<span class="number">5</span>)</span><br><span class="line">b=tf.mul(a，<span class="number">3</span>)</span><br><span class="line"><span class="comment">#利用默认的数据流图启动一个Session对象</span></span><br><span class="line">sess=tf.Session()</span><br><span class="line"><span class="comment">#定义一个字典，比如将a的值替换为15</span></span><br><span class="line">replace_dict=&#123;a：<span class="number">15</span>&#125;</span><br><span class="line"><span class="comment">#运行Session对象，将replace_dict赋给feed_dict</span></span><br><span class="line">sess.run(b，feed_dict=replace_dict)<span class="comment">#返回45</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">请注意，即便a的计算结果通常为7，我们传给eeddict的字典也会将它替换为15。在相当多的场合中，fed_dict都极为有用。由于张量的值是预先提供的，数据流图不再需要对该张量的任何普通依赖节点进行计算。这意味着如果有一个规模较大的数据流图，并希望用一些虚构的值对某些部分进行测试，TensorFlow将不会在不必要的计算上浪费时间。对于指定输入值，eed_dict也十分有用，在稍后的占位符一节中我们将对此进行介绍。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<h3 id="tfplacehold"><a class="markdownIt-Anchor" href="#tfplacehold"></a> tf.placehold</h3>
<p>之前定义的数据流图并未使用真正的“输入”，它总是使用相同的数值5和3。我们真正希望做的是从客户那里接收输入值，这样便可对数据流图中所描述的变换<br>
以各种不同类型的数值进行复用，借助“占位符”可达到这个目的。正如其名称所预示的那样，占位符的行为与Tesor对象一致，但在创建时无须为它们指定具体的数值。它们的作用是为运行时即将到来的某个Tensor对象预留位置，因此实际上变成了“输入”节点。利用tfplaceholderOp可创建占位符：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">inport numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#创建一个长度为2、数据类型为int32的占位向量</span></span><br><span class="line">a=tf.placeholder(tf.int32，shape=[<span class="number">2</span>]，name=<span class="string">"my_input"</span>)</span><br><span class="line"><span class="comment">#将该占位向量视为其他任意Tensor对象，加以使用</span></span><br><span class="line">b=tf.reduce_prod(a，name=<span class="string">"prod_b"</span>)</span><br><span class="line">c=tf.reduce_sum(a，name=<span class="string">"sum_c"</span>)</span><br><span class="line"><span class="comment">#完成数据流图的定义</span></span><br><span class="line">d=tf.add(b，c，name=<span class="string">"add_d"</span>)</span><br></pre></td></tr></table></figure>
<p>调用tf.placehoder()时，dtype参数是必须指定的，而shape参数可选：</p>
<ul>
<li>dtype指定了将传给该占位符的值的数据类型。该参数是必须指定的，因为需要确保不出现类型不匹配的错误。</li>
<li>shape指定了所要传入的Tensor对象的形状。请参考前文中对Tensor形状的讨论。shape参数的默认值为None，表示可接收任意形状的Tensor对象。<br>
与任何Op一样，也可在fpaceholer中指定一个name标识符。<br>
为了给占位符传入一个实际的值，需要使用Sesionnm()中的eed_dict参数。我们将指向占位符输出的句柄作为字典(在上述代码中，对应变量a)的“键”，而<br>
将希望传入的Tensor对象作为字典的“值”：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义一个TensorFlow Session对象</span></span><br><span class="line">sess=tf.Session()</span><br><span class="line"><span class="comment">#创建一个将传给feed_dict参数的字典</span></span><br><span class="line"><span class="comment">#键：a’，指向占位符输出Tensor对象的句柄</span></span><br><span class="line"><span class="comment">#值：一个值为[5，3]、类型为int32的向量</span></span><br><span class="line">input_dict=&#123;a:np.array([<span class="number">5</span>，<span class="number">3</span>]，dtype=np.int32)&#125;</span><br><span class="line"><span class="comment">#计算d的值，将input_dict的“值”传给a</span></span><br><span class="line">sess.run(d，feed_dict=input_dict)</span><br></pre></td></tr></table></figure>
<p>必须在eed dixt中为待计算的节点的每个依赖占位符包含一个键值对。在上面的代码中，需要计算d的输出，而它依赖于a的输出。如果还定义了一些d不依赖的其他占位符，则无需将它们包含在eed_dict中。<br>
placeholder的值是无法计算的—如果试图将其传入Session.nn()，将引发一个异常。</p>
<h3 id="variable对象"><a class="markdownIt-Anchor" href="#variable对象"></a> Variable对象</h3>
<h4 id="1创建variable对象"><a class="markdownIt-Anchor" href="#1创建variable对象"></a> 1.创建Variable对象</h4>
<p>Tensor对象和Op对象都是不可变的(immmtable)，但机器学习任务的本质决定了需要一种机制保存随时间变化的值。借助TensorFbw中的Varable对象，便可达到这个目的。Variabe对象包含了在对Session.un()多次调用中可持久化的可变张量值。Variabk对象的创建可通过Variabe类的构造方法tVariable()完成：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">inport tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#为Variable对象传入一个初始值3</span></span><br><span class="line">my_var=tf.Variable(<span class="number">3</span>，name=<span class="string">"my_variable"</span>)</span><br><span class="line"><span class="comment">#Variable对象可用于任何可能会使用Tensor对象的TensorFlbw函数或Op中，其当前值将传给使用它的Op：</span></span><br><span class="line">add=tf.add(<span class="number">5</span>，my_var)</span><br><span class="line">mul=tf.mul(<span class="number">8</span>，my_var)</span><br><span class="line"><span class="comment">#Variables对象的初值通常是全0、全1或用随机数填充的阶数较高的张量。为使创建具有这些常见类型初值的张量更加容易，TensorFlow提供了大量辅助Op，如tferos()、tfones()、tfrandom normal()和tfrandomuiform()，每个Op都接收一个sape参数，以指定所创建的Tensor对象的形状：</span></span><br><span class="line"><span class="comment">#2×2的零矩阵</span></span><br><span class="line">zeros=tf.zeros([<span class="number">2</span>，<span class="number">2</span>])</span><br><span class="line"><span class="comment">#长度为6的全1向量</span></span><br><span class="line">ones=tf.ones([<span class="number">6</span>])</span><br><span class="line"><span class="comment">#3×3×3的张量，其元素服从0~10的均匀分布</span></span><br><span class="line">uniform=tf.random_uniform([<span class="number">3</span>，<span class="number">3</span>，<span class="number">3</span>]，minval=<span class="number">0</span>，maxval=<span class="number">10</span>)</span><br><span class="line"><span class="comment">#3×3×3的张量，其元素服从0均值、标准差为2的正态分布</span></span><br><span class="line">normal=tf.random_normal([<span class="number">3</span>，<span class="number">3</span>，<span class="number">3</span>]，mean=<span class="number">0.0</span>，stddev=<span class="number">2.0</span>)</span><br></pre></td></tr></table></figure>
<p>除了tfrandom normal()外，经常还会看到人们使用ttrmncated nomal()，因为它不会创建任何<strong>偏离均值超过2倍标准差的值</strong>，从而可以防止有一个或两个元素与该张量中的其他元素显著不同的情况出现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#该Tensor对象不会返回任何小于3.0或大于7.0的值</span></span><br><span class="line">trunc=tf.truncated_normal([<span class="number">2</span>，<span class="number">2</span>]，mean=<span class="number">5.0</span>，stddev=<span class="number">1.0</span>)</span><br><span class="line">可像手工初始化张量那样将这些Op作为Variable对象的初值传入：</span><br><span class="line"><span class="comment">#默认均值为0，默认标准差为1.0</span></span><br><span class="line">randon_var=tf.Variable(tf.truncated_normal([<span class="number">2</span>，<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>
<h4 id="2variable对象的初始化"><a class="markdownIt-Anchor" href="#2variable对象的初始化"></a> 2.Variable对象的初始化</h4>
<p>Variable对象与大多数其他TensorFlow对象在Graph中存在的方式都比较类似，但它们的状态实际上是由Session对象管理的。因此，为使用Varinbe对象，需要采取一些额外的步骤—必须在一个Session对象内对Variable对象进行初始化。这样会使Session对象开始追踪这个Variable对象的值的变化。Varabe对象的初始化通常是通过将tinitialize_all_variabkes()Op传给Sessionrun()完成的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">init=tf.initialize_all_variables()</span><br><span class="line">sess=tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="comment">#如果只需要对数据流图中定义的一个Variable对象子集初始化，可使用tfinitialie variables()。该函数可接收一个要进行初始化的Variable对象列表：</span></span><br><span class="line">var1=tf.Variable(<span class="number">0</span>，name=<span class="string">"initialize_me"</span>)</span><br><span class="line">var2=tf.Variable(<span class="number">1</span>，name=<span class="string">"no_initialization"</span>)</span><br><span class="line">init=tf.initialize_variables([var1]，name=<span class="string">"init_var1"</span>)</span><br><span class="line">sess=tf.Session()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<h4 id="3variable对象的修改"><a class="markdownIt-Anchor" href="#3variable对象的修改"></a> 3.Variable对象的修改</h4>
<p>要修改Variablk对象的值，可使用Variable.assign()方法。该方法的作用是为Variable对象赋予新值。请注意，Variable.assign()是一个Op，要使其生效必须在一个Session对象中运行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个初值为1的Variable对象</span></span><br><span class="line">my_var=tf.Variable(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#创建一个Op，使其在每次运行时都将该Variable对象乘以2</span></span><br><span class="line">my_var_times_two=my_var.assign(my_var*<span class="number">2</span>)</span><br><span class="line"><span class="comment">#初始化Op init=tf.initialize_all_variables()</span></span><br><span class="line"><span class="comment">#启动一个会话</span></span><br><span class="line">sess=tf.Session()</span><br><span class="line"><span class="comment">#初始化Variable对象</span></span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="comment">#将Variable对象乘以2，并将其返回</span></span><br><span class="line">sess.run(my_var_times_two)</span><br><span class="line"><span class="comment">##输出：2</span></span><br><span class="line"><span class="comment">#再次相乘</span></span><br><span class="line">sess.run(my_var_times_two)</span><br><span class="line"><span class="comment">##输出：4</span></span><br><span class="line"><span class="comment">#再次相乘</span></span><br><span class="line">sess.run(my_var_times_two)</span><br><span class="line"><span class="comment">##输出：8</span></span><br><span class="line">对于Variablk对象的简单自增和自减，TensorFlow提供了Variable.asign add()方法和Variable.assignsub()方法：</span><br><span class="line"><span class="comment">#自增1</span></span><br><span class="line">sess.run(my_var.assign_add(<span class="number">1</span>))</span><br><span class="line"><span class="comment">#自减1</span></span><br><span class="line">sess.run(my_var.assign_sub(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>△由于不同Session对象会各自独立地维护Varablk对象的值，因此每个Session对象都拥有自己的、在Graph对象中定义的Variabe对象的当前值：</p>
<h4 id="4trainable参数"><a class="markdownIt-Anchor" href="#4trainable参数"></a> 4.trainable参数</h4>
<p>在本书的后续章节将介绍各种能够自动训练机器学习模型的Optinmizer类，这意味着这些类将自动修改Variable对象的值，而无须显式做出请求。在大多数情况下，这与读者的期望一致，但如果要求Graph对象中的一些Variabk对象只可手工修改，而不允许使用Optimizer类时，可在创建这些Variable对象时将其raimbe参数设为False：not_trainable=tf.Variable(0，trainable=False)</p>
</article><!-- lincense--><div class="license-wrapper"><p> <span>Author:  </span><a href="https://nymrli.top">Mrli</a></p><p> <span>Link:  </span><a href="https://nymrli.top/2019/09/19/深度学习/">https://nymrli.top/2019/09/19/深度学习/</a></p><p> <span>Copyright:  </span><span>All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/3.0">CC BY-NC-SA 3.0</a> unless stating additionally.</span></p></div><div class="post-paginator"><a class="prevSlogan" href="/2019/09/21/搭建Jupyter服务器/" title="搭建Jupyter、JupyterLab服务器"><span>< PreviousPost</span><br><span class="prevTitle">搭建Jupyter、JupyterLab服务器</span></a><a class="nextSlogan" href="/2019/09/17/常用域名记录解释/" title="常用域名记录解释"><span>NextPost ></span><br><span class="nextTitle">常用域名记录解释</span></a><div class="clear"></div></div><div id="comment"><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  id: '深度学习',
  owner: 'Freedomisgood',
  repo: 'Freedomisgood.github.io',
  oauth: {
    client_id: 'bc5a81fe36017dcd8b63',
    client_secret: '949cec3a1b91742c6249c47259791e4b80a6fa69',
  },
})
gitment.render('container')</script></div></section></article><footer id="cxo-footer-outer"><div id="cxo-footer-inner"><p class="footer-container"><span>Site by </span><a href="http://hexo.io"><span>Hexo</span></a><span> | theme </span><a href="https://github.com/Longlongyu/hexo-theme-Cxo"><span>Cxo</span></a></p><p class="beian"><span>备案号:苏ICP备18015439号</span></p><i class="fa fa-user"> </i><span id="busuanzi_value_site_uv"></span><span> | </span><i class="fa fa-eye"> </i><span id="busuanzi_value_site_pv"></span></div></footer><!-- catelog--><div class="toc-wrapper" style="top: 60vh;"><div class="toc-catalog"><i class="fa fa-list"> </i><span>CATALOG</span></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#深度学习神经网络"><span class="toc-number">1.</span> <span class="toc-text"> 深度学习——神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#构建网络的总原则"><span class="toc-number">1.1.</span> <span class="toc-text"> 构建网络的总原则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归"><span class="toc-number">1.2.</span> <span class="toc-text"> 线性回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#激活函数"><span class="toc-number">1.3.</span> <span class="toc-text"> 激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sigmod"><span class="toc-number">1.3.1.</span> <span class="toc-text"> sigmod:</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#logistic"><span class="toc-number">1.3.1.1.</span> <span class="toc-text"> logistic:</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#relu"><span class="toc-number">1.3.2.</span> <span class="toc-text"> reLU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tanh"><span class="toc-number">1.3.3.</span> <span class="toc-text"> tanh</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tensorflow"><span class="toc-number">1.4.</span> <span class="toc-text"> Tensorflow:</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tensorflow机器学习项目实战笔记"><span class="toc-number">2.</span> <span class="toc-text"> 《TensorFlow机器学习项目实战》笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#张量"><span class="toc-number">2.1.</span> <span class="toc-text"> 张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#numpy数组到tensorflow张量"><span class="toc-number">2.2.</span> <span class="toc-text"> numpy数组到TensorFlow张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#变量"><span class="toc-number">2.3.</span> <span class="toc-text"> 变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#placehold"><span class="toc-number">2.4.</span> <span class="toc-text"> placehold</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#会话"><span class="toc-number">2.5.</span> <span class="toc-text"> 会话</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#logit函数"><span class="toc-number">2.6.</span> <span class="toc-text"> logit函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#logistic函数"><span class="toc-number">2.7.</span> <span class="toc-text"> logistic函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#感知器算法"><span class="toc-number">2.8.</span> <span class="toc-text"> 感知器算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tensorflow中损失优化方法"><span class="toc-number">2.9.</span> <span class="toc-text"> TensorFlow中损失优化方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sklearn预处理函数"><span class="toc-number">2.10.</span> <span class="toc-text"> Sklearn预处理函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#书籍推荐"><span class="toc-number">2.11.</span> <span class="toc-text"> 书籍推荐</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hello-tensorflow"><span class="toc-number">2.12.</span> <span class="toc-text"> Hello TensorFlow</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sesstfsession"><span class="toc-number">2.12.1.</span> <span class="toc-text"> sess=tf.Session()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tfplacehold"><span class="toc-number">2.12.2.</span> <span class="toc-text"> tf.placehold</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#variable对象"><span class="toc-number">2.12.3.</span> <span class="toc-text"> Variable对象</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1创建variable对象"><span class="toc-number">2.12.3.1.</span> <span class="toc-text"> 1.创建Variable对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2variable对象的初始化"><span class="toc-number">2.12.3.2.</span> <span class="toc-text"> 2.Variable对象的初始化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3variable对象的修改"><span class="toc-number">2.12.3.3.</span> <span class="toc-text"> 3.Variable对象的修改</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4trainable参数"><span class="toc-number">2.12.3.4.</span> <span class="toc-text"> 4.trainable参数</span></a></li></ol></li></ol></li></ol></li></ol></div><!-- top--><i class="fa fa-arrow-up close" id="go-up" aria-hidden="true"></i></body></html>